<!DOCTYPE html><html lang=en><meta http-equiv=Content-Type content="text/html;charset=utf-8"> <meta http-equiv=X-UA-Compatible content="IE=edge"> <meta name=viewport content="width=device-width, initial-scale=1"><title>Duplicity SSH backends</title><meta name=description content="I have been using Duplicity to back up one of my Linux servers for several years now. Duplicity supports quite a few network protocols for connecting to file..."> <link rel=stylesheet href=/css/main.css> <script>!function(e,t,a,n,c,o,s){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,o=t.createElement(a),s=t.getElementsByTagName(a)[0],o.async=1,o.src=n,s.parentNode.insertBefore(o,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-34500030-2","auto"),ga("send","pageview");</script><main><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class=post-header><h1 class=post-title itemprop="name headline">Duplicity SSH backends</h1><p class=post-meta><time datetime=2017-12-02T00:00:00-05:00 itemprop=datePublished>Dec 2, 2017</time> • <span itemprop=author itemscope itemtype=http://schema.org/Person><span itemprop=name>Stephen Checkoway</span></span></div><div class=post-content itemprop=articleBody><p>I have been using <a href=http://duplicity.nongnu.org/>Duplicity</a> to back up one of my Linux servers for several years now. Duplicity supports quite a few network protocols for connecting to file servers, including commercial servers like Amazon S3, Google Drive, and Microsoft Azure. For my personal use, I’ve only used its ability to use SSH to back up to a small <a href=https://en.wikipedia.org/wiki/Network-attached_storage>NAS</a>. I have not been completely happy with Duplicity, but I have successfully used it to restore data lost from a hard drive failure so I’ve continued using it. Recently, I’ve discovered a number of issues, one of which I want to briefly discuss here, namely performance.<p><strong>This was written in early December, 2017. it’s entirely possible that the problem discussed below has been fixed.</strong><p>At some point in the last year, presumably after an <code class=highlighter-rouge>apt-get upgrade</code>, Duplicity stopped performing backups <em>at all</em>.<sup id=fnref:1><a href=#fn:1 class=footnote>1</a></sup> While fixing that issue a few days ago, I discovered that at some point, Duplicity’s performance had become abysmal.<p>My setup is that every day, I perform an incremental backup and once a month, I perform a full backup. The full backup involves compressing about 40 GB of data, GPG encrypting and signing, and transferring about 20 GB of data to my NAS over SSH.<p>Previously, this operation would take about four and a half hours. After upgrading Duplicity, it was taking more than 47 hours.<p>Apparently, a new, default SSH backend was introduced using <a href=http://www.paramiko.org/>Paramiko</a>, replacing the old SSH backend which used <a href=https://pexpect.readthedocs.io/en/stable/>Pexpect</a> and the system <code class=highlighter-rouge>ssh</code> and <code class=highlighter-rouge>sftp</code> binaries. The duplicity <a href=http://duplicity.nongnu.org/duplicity.1.html>man page</a> says that the advantages of Paramiko over Pexpect are “speed and maintainability.”<p>Some Googling suggests that Paramiko might not be so speedy after all, at least not with its default settings.<p>To compare the two SSH backends, I performed two full backups, first with the default Paramiko, and then with Pexpect. For some reason, Duplicity’s <code class=highlighter-rouge>--progress</code> option is completely broken so I made do with a somewhat primitive approach: Duplicity stores encrypted “volumes” with a default size of 200 MB. By calculating the difference between the modified time of volume file <em>n</em> and the modified time of the first volume file, I can plot how long it took Duplicity to backup volumes 2 through <em>n</em>.<sup id=fnref:2><a href=#fn:2 class=footnote>2</a></sup><p style=text-align:cente><img src=/assets/posts/duplicity/performance.png alt="Duplicity performance graph"><p>As you can see, Paramiko performs substantially worse than Pexpect. Hopefully, the Duplicity developers will fix this pretty major performance regression. In the meantime, using Pexpect seems like a pretty good fix.<p>Andrew Jeffery <a href=https://twitter.com/mramboar/status/936812790525829120>suggests</a> that I check out <a href=https://borgbackup.readthedocs.io/en/stable/>Borg Backup</a>. From reading the documentation, it looks pretty good. I plan to try it out. With luck, I can ditch Duplicity altogether.<p>All of the code and data for this post is on <a href=https://github.com/stevecheckoway/duplicity-performance>GitHub</a>.<hr><div class=footnotes><ol><li id=fn:1><p>My list of files to exclude also contained files to include. These were superfluous so the Duplicity developers apparently decided to make this an error and not perform backups. <a href=#fnref:1 class=reversefootnote>↩</a><li id=fn:2><p>The time for volume 1 cannot be handled in this fashion because although I know the start time of the backup, Duplicity performs a bunch of work before it begins transferring files. Linux (at least the version running on my NAS) doesn’t expose file creation times so I cannot use that for the first volume either. <a href=#fnref:2 class=reversefootnote>↩</a></ol></div></div></article></main>